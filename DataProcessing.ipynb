{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwmitz/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://worldhappiness.report/ed/2024/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "excel_link = None\n",
    "for link in soup.find_all('a'):\n",
    "    if \"Data for Table 2.1\" in link.get_text():\n",
    "        excel_link = link.get('href')\n",
    "        break\n",
    "\n",
    "if excel_link:\n",
    "    # Download the excel file\n",
    "    excel_response = requests.get(excel_link)\n",
    "\n",
    "    # Save the excel file\n",
    "    with open(\"data2/world_happiness_data.xlsx\", \"wb\") as f:\n",
    "        f.write(excel_response.content)\n",
    "\n",
    "    # Convert the excel file to csv\n",
    "    df = pd.read_excel(\"data2/world_happiness_data.xlsx\")\n",
    "    df.to_csv(\"data2/world_happiness_data.csv\", index=False)\n",
    "\n",
    "    # Delete the excel file\n",
    "    os.remove(\"data2/world_happiness_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turing into JSON for Better Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data = {}\n",
    "\n",
    "with open(\"data2/world_happiness_data.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        country = row[\"Country name\"]\n",
    "        year = row[\"year\"]\n",
    "        data = {key: value for key, value in row.items() if key not in [\"Country name\", \"year\"]}\n",
    "\n",
    "        # Check if any value in the data dictionary is empty\n",
    "        if not all(data.values()):\n",
    "            data = {key: None if value == \"\" else value for key, value in data.items()}\n",
    "\n",
    "        if country not in country_data:\n",
    "            country_data[country] = {}\n",
    "\n",
    "        country_data[country][year] = data\n",
    "\n",
    "json_data = json.dumps(country_data)\n",
    "with open(\"data2/world_happiness_data.json\", \"w\") as f:\n",
    "    f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to Individual JSON Files for Each Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data2/world_happiness_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to hold data for each attribute\n",
    "attribute_data = {}\n",
    "\n",
    "# Extract data for each attribute\n",
    "for country, years in data.items():\n",
    "    for year, attributes in years.items():\n",
    "        for attribute, value in attributes.items():\n",
    "            # Initialize the country in attribute_data if it's not already there\n",
    "            if attribute not in attribute_data:\n",
    "                attribute_data[attribute] = {}\n",
    "            if country not in attribute_data[attribute]:\n",
    "                attribute_data[attribute][country] = {}\n",
    "\n",
    "            # Add the year and value for the country in the attribute-specific dictionary\n",
    "            attribute_data[attribute][country][year] = float(value) if value else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Values for Each Attribute for Easier Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make every value between 0 and 10, so we need to update for each attribute accordingly\n",
    "for attribute, countries in attribute_data.items():\n",
    "    if attribute == \"Life Ladder\" or attribute == \"Log GDP per capita\":\n",
    "        continue\n",
    "    if attribute == \"Healthy life expectancy at birth\":\n",
    "        for country, years in countries.items():\n",
    "            for year, value in years.items():\n",
    "                if value:\n",
    "                    attribute_data[attribute][country][year] = value / 10\n",
    "    else:\n",
    "        for country, years in countries.items():\n",
    "            for year, value in years.items():\n",
    "                if value:\n",
    "                    attribute_data[attribute][country][year] = value * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, save each attribute data into a separate JSON file\n",
    "for attribute, values in attribute_data.items():\n",
    "    file_name = attribute.replace(\" \", \"_\").lower() + \".json\"\n",
    "    with open(f\"data2/{file_name}\", \"w\") as f:\n",
    "        json.dump(values, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Sure TOPO.JSON Countries Align with World Happiness Report Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bahrain',\n",
       " 'Comoros',\n",
       " 'Hong Kong S.A.R. of China',\n",
       " 'Ivory Coast',\n",
       " 'Maldives',\n",
       " 'Malta',\n",
       " 'Mauritius',\n",
       " 'North Macedonia',\n",
       " 'Singapore'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data2/world_happiness_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"data2/countries.topo.json\", \"r\") as f:\n",
    "    countries = json.load(f)\n",
    "\n",
    "countries_topo = countries['objects']['countries']['geometries']\n",
    "countries_topo = {country['properties']['name'] for country in countries_topo}\n",
    "\n",
    "countries_data = {country for country in data}\n",
    "\n",
    "# Find countries that aren't in topojson but are in the data\n",
    "missing_countries = countries_data - countries_topo\n",
    "missing_countries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
